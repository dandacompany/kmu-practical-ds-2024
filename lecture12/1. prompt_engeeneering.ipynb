{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프롬프트 엔지니어링\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Using cached yfinance-0.2.40-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from yfinance) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from yfinance) (2.31.0)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Using cached multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting lxml>=4.9.1 (from yfinance)\n",
      "  Using cached lxml-5.2.2-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from yfinance) (4.2.1)\n",
      "Requirement already satisfied: pytz>=2022.5 in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from yfinance) (2024.1)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Using cached frozendict-2.4.4-py312-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Using cached peewee-3.17.5-py3-none-any.whl\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from yfinance) (4.12.3)\n",
      "Collecting html5lib>=1.1 (from yfinance)\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2024.2.2)\n",
      "Using cached yfinance-0.2.40-py2.py3-none-any.whl (73 kB)\n",
      "Using cached frozendict-2.4.4-py312-none-any.whl (16 kB)\n",
      "Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Using cached lxml-5.2.2-cp312-cp312-macosx_10_9_universal2.whl (8.2 MB)\n",
      "Using cached multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Installing collected packages: peewee, multitasking, lxml, html5lib, frozendict, yfinance\n",
      "Successfully installed frozendict-2.4.4 html5lib-1.1 lxml-5.2.2 multitasking-0.0.11 peewee-3.17.5 yfinance-0.2.40\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 30\n",
      "Python-dotenv could not parse statement starting at line 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from utils.exchange import convert_usd_to_krw\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* OpenAI API서비스는 상용 언어모델 서비스로 토큰당 청구되는 유료 서비스이다.\n",
    "* 가격표 (출처 : https://openai.com/api/pricing/)\n",
    "  \n",
    "  * 대표모델 API 사용료 ( 24/5/19 현재 )\n",
    "   \n",
    "     | 모델명                  | 1M 토큰당 가격 (입력) | 1M 토큰당 가격 (출력) |\n",
    "     |-------------------------|-----------------------|-----------------------|\n",
    "     | gpt-3.5-turbo-0125      | $0.5                  | $1.5                  |\n",
    "     | gpt-3.5-turbo-instruct  | $1.5                  | $2                    |\n",
    "     | gpt-4o                  | $5                    | $15                   |\n",
    "     | gpt-4 turbo             | $10                   | $30                   |\n",
    "     | gpt-4                   | $30                   | $60                   |\n",
    "     | gpt-4 32k               | $60                   | $120                  |\n",
    "\n",
    "  <br/>\n",
    "  \n",
    "  * Fine-Tuning모델 API 사용료 (24/5/19 현재)\n",
    "   \n",
    "     | 모델명         | 훈련 비용 (입력) | 사용 비용 (입력) | 사용 비용 (출력) |\n",
    "     |----------------|------------------|------------------|------------------|\n",
    "     | gpt-3.5-turbo  | $8.00 / 1M 토큰  | $3.00 / 1M 토큰  | $6.00 / 1M 토큰  |\n",
    "     | davinci-002    | $6.00 / 1M 토큰  | $12.00 / 1M 토큰 | $12.00 / 1M 토큰 |\n",
    "     | babbage-002    | $0.40 / 1M 토큰  | $1.60 / 1M 토큰  | $1.60 / 1M 토큰  |\n",
    "\n",
    "\n",
    "  <br/>\n",
    "  \n",
    "   * 임베딩모델 API 사용료 (24/5/19 현재)\n",
    "      \n",
    "        | 모델명                  | 1M 토큰당 가격       |\n",
    "        |-------------------------|----------------------|\n",
    "        | text-embedding-3-small  | $0.02                |\n",
    "        | text-embedding-3-large  | $0.13                |\n",
    "        | ada v2                  | $0.10                |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dante/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# 언어모델 로드 \n",
    "gpt35 = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "* 제로샷\n",
    "  \n",
    "  * 방식: 어떤 예제도 보여주지 않고 요청사항을 직접적으로 전달하는 방식\n",
    "  \n",
    "  * 핵심 개념: 기본 모델의 훈련 체크포인트에 전적으로 의존한다.\n",
    "  * 특징: 모델이 해당 주제에 대한 충분한 정보를 갖고 있지 않을 수 있으므로, 답변의 정확성이 떨어질 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1. 데이터 분석가 (Data Analyst)\\n'\n",
      " '2. 데이터 과학자 (Data Scientist)\\n'\n",
      " '3. 비즈니스 인텔리전스 애널리스트 (Business Intelligence Analyst)\\n'\n",
      " '4. 데이터 엔지니어 (Data Engineer)\\n'\n",
      " '5. 데이터 웨어하우스 전문가 (Data Warehouse Specialist)\\n'\n",
      " '6. 데이터 마이닝 전문가 (Data Mining Specialist)\\n'\n",
      " '7. 데이터 시각화 전문가 (Data Visualization Specialist)\\n'\n",
      " '8. 빅데이터 아키텍트 (Big Data Architect)\\n'\n",
      " '9. 데이터베이스 관리자 (Database Administrator)\\n'\n",
      " '10. 인공지능 엔지니어 (AI Engineer)')\n",
      "┌──────────────────────────────┐\n",
      "│          0.50원 사용          │\n",
      "└──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"{category} 에 해당하는 직무의 종류는 무엇이 있나요? {num}개를 소개해주세요.\",\n",
    "    input_variables=[\"category\", \"num\"]\n",
    ")\n",
    "chain = prompt | gpt35\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    resp = chain.invoke({\"category\": \"데이터\", \"num\": 10})\n",
    "    pprint(resp.content)\n",
    "    convert_usd_to_krw(cb.total_cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "* 퓨샷\n",
    "  \n",
    "    * 방식: 명시적인 지침이 없이 요청사항과 관련된 몇가지 입력과 출력 예제를 제공\n",
    "    \n",
    "    * 핵심개념 : 요청내용의 의도와 목표를 예제로부터 자연스럽게 추론하도록 유도\n",
    "    * 특징 : 퓨샷은 추론 능력을 향상시키지만, 데이터 변동성에 취약함. 명시적 지침을 추가하는 방법으로 더 개선이 가능함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AI 모델러는 인공지능 모델을 개발하고 최적화하여 다양한 데이터 소스로부터 패턴을 발견하고 예측 모델을 구축합니다. 또한 모델의 정확성과 '\n",
      " '성능을 향상시키기 위해 테스트 및 평가를 수행하며, 실제 시스템에 통합하여 실시간 예측을 가능하게 합니다.')\n",
      "┌──────────────────────────────┐\n",
      "│          0.37원 사용          │\n",
      "└──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    template=\"{question} -> {answer}\",\n",
    "    input_variables=[\"question\", \"answer\"]\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"question\": \"데이터 분석가는 어떤 일을 하나요?\", \"answer\": \"데이터 분석가는 데이터를 수집, 처리, 분석하여 유의미한 인사이트 도출\"},\n",
    "    {\"question\": \"데이터 엔지니어는 어떤 일을 하나요?\", \"answer\": \"데이터 엔지니어는 데이터 파이프라인을 설계하고 구축하여 데이터를 효율적으로 처리하고 저장함.\"}\n",
    "]\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    prefix=\"다음은 데이터 직무에 대한 예시입니다:\",\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"질문: {question}\",\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "chain = prompt | gpt35\n",
    "with get_openai_callback() as cb:\n",
    "    resp = chain.invoke({\"question\": \"AI 모델러는 어떤 일을 하나요?\"})\n",
    "    pprint(resp.content)\n",
    "    convert_usd_to_krw(cb.total_cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "* Self-Consistency Prompting\n",
    "\n",
    "    * 방식 : 질문에 대해 여러 후보 답변을 생성하고 가장 일관되거나 가장 빈번한 답변이 최종 답변으로 채택\n",
    "  \n",
    "    * 특징: 팩트체크 또는 정보 통합이 필요한 경우 활용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dante/miniconda3/envs/langchain/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "solutions_prompt = PromptTemplate(\n",
    "    template=\"\"\"다음 요청 사항에 대한 {count}개의 중복되지 않는 답변을 생성하세요 : \n",
    "    {request}\n",
    "    * 응답 목록 :\n",
    "    \"\"\",\n",
    "    input_variables=[\"count\", \"request\"]\n",
    ")\n",
    "\n",
    "solutions_chain = LLMChain(\n",
    "    llm=gpt35,\n",
    "    prompt=solutions_prompt,\n",
    "    output_key=\"solutions\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    * 제시된 응답 목록: {solutions}\n",
    "    * 요청 : 각 응답에 대해 몇번이나 발생할지 카운팅을 해봐. 그리고, 그중에서 가장 많이 등장하는 답변을 선택해줘\n",
    "    * 가장 많이 등장하는 응답:\n",
    "    \"\"\",\n",
    "    input_variables=[\"solutions\"]\n",
    ")\n",
    "\n",
    "consistency_chain = LLMChain(\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-0125\"),\n",
    "    prompt=consistency_prompt,\n",
    "    output_key=\"final_solution\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_chain = SequentialChain(\n",
    "    chains=[solutions_chain, consistency_chain],\n",
    "    input_variables=[\"count\", \"request\"],\n",
    "    output_variables=[\"final_solution\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('3. 데이터 분석가는 분석 능력 뿐만 아니라 엔지니어링 지식도 필요합니다. 데이터를 수집하고 처리하는 과정을 이해하면 분석 작업이 '\n",
      " '원활해집니다. (2번)')\n"
     ]
    }
   ],
   "source": [
    "resp = answer_chain.run(count=5, request=\"데이터 분석가는 분석만 잘하면 되는거야? 엔지니어링은 몰라도되지?\")\n",
    "pprint(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "* CoT (Chain-of-Thought) Prompting\n",
    "\n",
    "  * 방식: 문제 해결 과정을 단계별로 설명하면서 답을 도출하는 기법\n",
    "  \n",
    "  * 핵심 개념: 모델이 논리적 사고 과정을 거치도록 하여 복잡한 문제를 해결하도록 유도\n",
    "  * 특징: 제로샷 CoT, 퓨샷 CoT 으로 응용이 가능함.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "* MinToMax Prompting\n",
    "\n",
    "    * 방식 및 개념: 단순한 질문부터 시작하여 점차 복잡한 질문으로 진행하는 기법\n",
    "  \n",
    "    * 특징 : 단계별 난이도 설정이 중요하며, 초기 단계에서 모델이 충분히 학습할 수 있도록 간단한 질문을 제공해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 중학교 수학 문제 예시\n",
    "  \n",
    "    <img src=\"./images/formula1.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문제 식 : $\\lim_{x \\to 0} \\frac{\\tan\\left(\\frac{x}{5}\\right)}{\\sin(2x)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = r\"\\[\\lim_{x \\to 0} \\frac{\\tan\\left(\\frac{x}{5}\\right)}{\\sin(2x)}\\]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('먼저 주어진 함수를 0/0 형태로 변형하기 위해 미분의 정의를 사용합니다.\\n'\n",
      " '\\n'\n",
      " '\\\\[\\\\lim_{x \\\\to 0} \\\\frac{\\\\tan\\\\left(\\\\frac{x}{5}\\\\right)}{\\\\sin(2x)} = '\n",
      " '\\\\lim_{x \\\\to 0} '\n",
      " '\\\\frac{\\\\frac{\\\\tan\\\\left(\\\\frac{x}{5}\\\\right)}{\\\\frac{x}{5}}}{\\\\frac{\\\\sin(2x)}{2x}}\\\\]\\n'\n",
      " '\\n'\n",
      " '여기서 분자와 분모의 극한값을 구하기 위해 미분의 정의인 \\\\(\\\\lim_{t \\\\to 0} \\\\frac{\\\\tan(t)}{t} = '\n",
      " '1\\\\)과 \\\\(\\\\lim_{t \\\\to 0} \\\\frac{\\\\sin(t)}{t} = 1\\\\)을 사용합니다.\\n'\n",
      " '\\n'\n",
      " '따라서 위의 식은 다음과 같이 변형됩니다.\\n'\n",
      " '\\n'\n",
      " '\\\\[ = \\\\frac{1}{2} \\\\cdot 1 = \\\\frac{1}{2}\\\\]\\n'\n",
      " '\\n'\n",
      " '따라서 \\\\(\\\\lim_{x \\\\to 0} \\\\frac{\\\\tan\\\\left(\\\\frac{x}{5}\\\\right)}{\\\\sin(2x)} '\n",
      " '= \\\\frac{1}{2}\\\\)입니다.')\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"다음 문제의 해답을 찾아주세요 : {formula}\",\n",
    "    input_variables=[\"formula\"]\n",
    ")\n",
    "\n",
    "resp = (prompt | gpt35).invoke({\"formula\": formula})\n",
    "pprint(resp.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "streaming_llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'분자의 식은 tan(x/5)이고, x->0일때, tan(x)는 x에 근사하므로 tan(x/5)는 x/5에 근사합니다. 따라서 분자의 근사식은 x/5입니다.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ConversationChain(llm=streaming_llm, memory=memory)\n",
    "chain.predict(input=r\"\\lim_{x \\to 0} \\frac{\\tan\\left(\\frac{x}{5}\\right)}{\\sin(2x)} 문제를 풀어보려고해. 분자의 식은 뭐지? 그리고 x->0일때, 그 식의 작은 근사식은 뭐지?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'분모의 식은 sin(2x)이고, x->0일때, sin(x)는 x에 근사하므로 sin(2x)는 2x에 근사합니다. 따라서 분모의 근사식은 2x입니다.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=\"그러면 분모식은 뭐지? x->0 일때, 그 식의 작은 근사식은 뭐지?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'분자의 근사식인 x/5를 분모의 근사식인 2x로 나누면, (x/5) / (2x) = 1/10 가 됩니다.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=\"분자의 작은 근사식을 분모의 작은 근사식으로 나누면 어떻게 되는 거지?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'전체식의 극한은 분자의 근사식을 분모의 근사식으로 나눈 값인 1/10이 됩니다. 따라서 \\\\lim_{x \\\\to 0} \\\\frac{\\\\tan\\\\left(\\\\frac{x}{5}\\\\right)}{\\\\sin(2x)} = 1/10 입니다.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=\"그러면 전체식의 극한은 어떻게 되는 거지?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='\\\\lim_{x \\\\to 0} \\\\frac{\\\\tan\\\\left(\\\\frac{x}{5}\\\\right)}{\\\\sin(2x)} 문제를 풀어보려고해. 분자의 식은 뭐지? 그리고 x->0일때, 그 식의 작은 근사식은 뭐지?'),\n",
       " AIMessage(content='분자의 식은 tan(x/5)이고, x->0일때, tan(x)는 x에 근사하므로 tan(x/5)는 x/5에 근사합니다. 따라서 분자의 근사식은 x/5입니다.'),\n",
       " HumanMessage(content='그러면 분모식은 뭐지? x->0 일때, 그 식의 작은 근사식은 뭐지?'),\n",
       " AIMessage(content='분모의 식은 sin(2x)이고, x->0일때, sin(x)는 x에 근사하므로 sin(2x)는 2x에 근사합니다. 따라서 분모의 근사식은 2x입니다.'),\n",
       " HumanMessage(content='분자의 작은 근사식을 분모의 작은 근사식으로 나누면 어떻게 되는 거지?'),\n",
       " AIMessage(content='분자의 근사식인 x/5를 분모의 근사식인 2x로 나누면, (x/5) / (2x) = 1/10 가 됩니다.'),\n",
       " HumanMessage(content='그러면 전체식의 극한은 어떻게 되는 거지?'),\n",
       " AIMessage(content='전체식의 극한은 분자의 근사식을 분모의 근사식으로 나눈 값인 1/10이 됩니다. 따라서 \\\\lim_{x \\\\to 0} \\\\frac{\\\\tan\\\\left(\\\\frac{x}{5}\\\\right)}{\\\\sin(2x)} = 1/10 입니다.')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 두번째 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"다음 문제의 해답을 찾아주세요 : {quiz}\",\n",
    "    input_variables=[\"quiz\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = \"\"\"\n",
    "    도둑을 쫓는 주인이 처음에는 도둑에게 37 리 뒤처져 있었습니다. 주인이 145 리를 이동한 후, \n",
    "    그는 이제 도둑에게 23 리 뒤처져 있었습니다. 따라서 그는 도둑에게 37 - 23 = 14 리를 따라잡은 것입니다.\n",
    "    주인이 145 리를 이동하여 14 리를 따라잡았다면, \n",
    "    23 리를 더 따라잡기 위해서는 몇 리를 더 이동해야 하나요?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('주인이 145 리를 이동하여 14 리를 따라잡았으므로, 도둑과의 거리는 145 - 14 = 131 리 입니다.\\n'\n",
      " '따라서 주인이 23 리를 더 따라잡기 위해서는 131 + 23 = 154 리를 더 이동해야 합니다. \\n'\n",
      " '즉, 주인은 총 154 리를 더 이동해야 도둑을 23 리 앞서게 됩니다.')\n"
     ]
    }
   ],
   "source": [
    "# 틀린 답을 말하는 GPT 3.5 turbo 모델\n",
    "chain = prompt | gpt35\n",
    "resp = chain.invoke({\"quiz\": quiz})\n",
    "pprint(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('문제를 해결하기 위해 다음과 같은 단계를 통해 접근할 수 있습니다.\\n'\n",
      " '\\n'\n",
      " '1. 주인이 145 리를 이동하여 14 리를 따라잡았다는 사실로부터, 주인이 도둑을 따라잡는 속도를 계산할 수 있습니다.\\n'\n",
      " '2. 주인이 14 리를 따라잡는 데 145 리를 이동했다면, 주인의 따라잡는 속도는 145 리/14 리 입니다.\\n'\n",
      " '3. 이제 주인이 23 리를 더 따라잡기 위해 몇 리를 더 이동해야 하는지 계산합니다.\\n'\n",
      " '\\n'\n",
      " '따라잡는 속도를 계산하면:\\n'\n",
      " '\\\\[ \\\\text{따라잡는 속도} = \\\\frac{145 \\\\text{ 리}}{14 \\\\text{ 리}} \\\\]\\n'\n",
      " '\\n'\n",
      " '주인이 23 리를 따라잡기 위해 이동해야 하는 거리는:\\n'\n",
      " '\\\\[ \\\\text{이동 거리} = \\\\frac{145 \\\\text{ 리}}{14 \\\\text{ 리}} \\\\times 23 \\\\text{ '\n",
      " '리} \\\\]\\n'\n",
      " '\\n'\n",
      " '이 계산을 하면:\\n'\n",
      " '\\\\[ \\\\text{이동 거리} =  \\\\frac{145}{14} \\\\times 23 \\\\]\\n'\n",
      " '\\\\[ \\\\text{이동 거리} = 10.3571 \\\\times 23 \\\\]\\n'\n",
      " '\\\\[ \\\\text{이동 거리} = 238.2143 \\\\text{ 리} \\\\]\\n'\n",
      " '\\n'\n",
      " '따라서, 주인이 23 리를 더 따라잡기 위해서는 약 238.2143 리를 더 이동해야 합니다. \\n'\n",
      " '\\n'\n",
      " '결론적으로, 주인은 도둑을 따라잡기 위해 238.2143 리를 더 이동해야 합니다.')\n"
     ]
    }
   ],
   "source": [
    "# 최신 멀티모달 모델인 GPT 4 옴니의 경우 문제의 정답을 말해준다.\n",
    "# 프롬프트 공학을 하지 않아도, 모델이 자체적으로 \n",
    "gpt4o = ChatOpenAI(model='gpt-4o')\n",
    "chain = prompt | gpt4o\n",
    "resp = chain.invoke({\"quiz\": quiz})\n",
    "pprint(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('* 첫번째 요청: 주인의 속도는 (37 - 23) 리를 145 리의 이동거리로 이동하는데 걸린 시간으로 구할 수 있습니다. \\n'\n",
      " '    속도 = 이동거리 / 시간 = 122 / 145 = 0.841 리/시간\\n'\n",
      " '* 두번째 요청: 23 리를 따라잡기 위해서는 (37 - 23) 리를 23 리의 이동거리로 이동하는데 걸리는 시간을 구해야 합니다. \\n'\n",
      " '    시간 = 이동거리 / 속도 = 14 / 0.841 = 16.64 시간\\n'\n",
      " '* 최종 답변: 23 리를 더 따라잡기 위해서는 16.64 시간을 더 이동해야 합니다.')\n"
     ]
    }
   ],
   "source": [
    "# GPT3.5 turbo 모델을 프롬프트 공학으로 재시도했으나 실패\n",
    "chain = prompt | gpt35\n",
    "\n",
    "resp = chain.invoke(input=f\"\"\"\n",
    "    * 퀴즈를 한번에 풀지 말고, 한단계씩 요청할거야.\n",
    "    * 퀴즈내용: {quiz}\n",
    "    * 첫번째 요청: 주인의 속도를 구해봐\n",
    "    * 두번째 요청: 23리를 움직이려면 지금 속도로 몇 리를 가야하니?\n",
    "    * 두번째 요청을 최종 답변으로 말해줘\n",
    "\"\"\")\n",
    "pprint(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT 3.5 turbo로 문제를 메모리 버퍼를 사용해 작은 문제에서 복잡한 문제로 단계적으로 질의하며 문제해결\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationChain(llm=gpt35, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'첫번째 요청에 대해 답변드리겠습니다. 주인이 145리를 이동하여 14리를 따라잡았으므로, 주인의 속도는 14리를 145리로 나눈 것이 됩니다. 따라서 주인의 속도는 14 / 145 = 0.0967 리/리 입니다. 이 부분에 대해 추가 질문이 있으실 경우 언제든지 물어보세요!'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=f\"\"\"\n",
    "    * 퀴즈를 한번에 풀지 말고, 한단계씩 요청할거야.\n",
    "    * 퀴즈내용: {quiz}\n",
    "    * 첫번째 요청: 주인의 속도를 구해봐\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'두번째 요청에 대해 답변드리겠습니다. 주인이 현재 속도인 0.0967 리/리로 23리를 더 따라잡기 위해서는 다음과 같이 계산할 수 있습니다. 주인이 23리를 따라잡으려면 23를 주인의 현재 속도로 나눈 값을 더해야 합니다. 따라서 23 / 0.0967 ≈ 237.73 리를 더 이동해야 23리를 따라잡을 수 있습니다. 이 부분에 대해 추가 질문이 있으실 경우 언제든지 물어보세요!'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=f\"\"\"\n",
    "    * 두번째 요청: 23리를 움직이려면 지금 속도로 몇 리를 가야하니?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "* CoD(Chain-of-Density)\n",
    "\n",
    "    * 방식 및 개념: 생성된 요약의 정보 밀도를 점진적으로 높이면서 길이를 제어하는 프롬프트 가이드\n",
    "  \n",
    "    * 특징: 요약에서 정보의 밀도를 향상시키는 효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"문화체육관광부가 발표한 '2023년 국민 독서실태' 결과에 따르면 성인의 독서율과 독서량이 계속해서 하락하고 있으며, 성인 10명 중 \"\n",
      " '6명은 1년 동안 아무 책도 읽지 않은 상황이다. 이러한 문제는 문해력 저하로 이어질 수 있으며, 문해력은 소통과 연결고리를 이루는 '\n",
      " '중요한 역할을 한다. 특히 비즈니스 현장에서는 문해력이 업무 능력과 직결되어 있어 중요하다. \\n'\n",
      " '\\n'\n",
      " '문해력을 향상시키기 위해서는 많이 읽고, 많이 쓰고, 많이 생각하는 것이 중요하다. 회사는 직원을 대상으로 문해력 향상 프로그램을 '\n",
      " '제공하고, 독서 모임을 추천하며, 문서 작성을 위한 공통적인 매뉴얼을 마련하는 등의 전략을 펼쳐야 한다. 개인의 노력뿐만 아니라 회사와 '\n",
      " '국가 차원에서도 적극적인 대응이 필요하다. 함께하는 힘이 필요한 시대이며, 문해력은 개인의 문제가 아닌 전체 사회의 문제로 인식되어야 '\n",
      " '한다.')\n",
      "┌──────────────────────────────┐\n",
      "│          2.59원 사용          │\n",
      "└──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# 제로샷 시도\n",
    "article = open(\"dataset/articles/article1.txt\").read()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"다음 아티클을 요약 및 정리해줘 : {article}\",\n",
    "    input_variables=[\"article\"]\n",
    ")\n",
    "chain = prompt | gpt35\n",
    "with get_openai_callback() as cb:\n",
    "    resp = chain.invoke({\"article\": article})\n",
    "    pprint(resp.content)\n",
    "    convert_usd_to_krw(cb.total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Missing entities: 문해력; 독서실태; 독서지표\\n'\n",
      " '\\n'\n",
      " 'Summary: 성인 문해력 저하 현상 심각. 문해력 논란 지속, 성인 독서율 하락. 성인 10명 중 6명 1년 동안 책 읽지 않음. '\n",
      " '문해력은 소통 중요, 글의 맥락 이해 필요.문해력은 소통을 위한 능력. OECD 조사 성인 문해력 중요성 강조. 성인 문해력 업무 능력과 '\n",
      " '직결. 문해력 높으면 업무 정확, 빠르게 처리.회사의 전략 필요, 직원 문해력 향상 프로그램 제공. 회사 내 독서 모임 추천. 회사에서 '\n",
      " '사용할 수 있는 공통적인 매뉴얼 필요. 함께 하는 힘이 필요한 시대.')\n",
      "┌──────────────────────────────┐\n",
      "│          2.50원 사용          │\n",
      "└──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# CoD 프롬프팅 시도\n",
    "# ref : https://arxiv.org/abs/2309.04269\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Article: {article}\n",
    "    You will generate increasingly concise, entity-dense summaries of the above article. \n",
    "\n",
    "    Repeat the following 2 steps 5 times. \n",
    "\n",
    "    Step 1. Identify 1-3 informative entities (\";\" delimited) from the article which are missing from the previously generated summary. \n",
    "    Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the missing entities. \n",
    "\n",
    "    A missing entity is:\n",
    "    - relevant to the main story, \n",
    "    - specific yet concise (5 words or fewer), \n",
    "    - novel (not in the previous summary), \n",
    "    - faithful (present in the article), \n",
    "    - anywhere (can be located anywhere in the article).\n",
    "\n",
    "    Guidelines:\n",
    "\n",
    "    - The first summary should be long (4-5 sentences, ~80 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~80 words.\n",
    "    - Make every word count: rewrite the previous summary to improve flow and make space for additional entities.\n",
    "    - Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n",
    "    - The summaries should become highly dense and concise yet self-contained, i.e., easily understood without the article. \n",
    "    - Missing entities can appear anywhere in the new summary.\n",
    "    - Never drop entities from the previous summary. If space cannot be made, add fewer new entities. \n",
    "    - In korean\n",
    "\n",
    "    Remember, use the exact same number of words for each summary.\n",
    "    \"\"\",\n",
    "    input_variables=[\"article\"]\n",
    ")\n",
    "chain = prompt | gpt35\n",
    "with get_openai_callback() as cb:\n",
    "    resp = chain.invoke({\"article\": article})\n",
    "    pprint(resp.content)\n",
    "    convert_usd_to_krw(cb.total_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('### 요약\\n'\n",
      " '\\n'\n",
      " '문화체육관광부가 발표한 ‘2023년 국민 독서실태’ 결과에 따르면 성인의 독서율과 독서량이 지속적으로 감소하고 있으며, 10명 중 6명은 '\n",
      " '1년 동안 책을 읽지 않았다. 문해력 저하로 인한 사회적 파장은 크며, 이는 소통의 문제를 야기한다. 문해력은 단순히 글을 읽고 쓸 수 '\n",
      " '있는 능력을 넘어, 글의 맥락을 이해하고 의도를 명확하게 전달하는 능력을 포함한다. 성인의 문해력은 업무 효율성과 직결되며, 세대 간 '\n",
      " '문해력 차이로 인해 직장에서의 소통 문제가 발생하기도 한다.\\n'\n",
      " '\\n'\n",
      " '비즈니스 현장에서 문해력은 중요한데, 보고서 작성과 같은 업무에서 문해력이 부족하면 소통의 어려움과 갈등이 초래된다. 이를 해결하기 '\n",
      " '위해서는 회사 차원의 전략적 접근이 필요하다. 전문가들은 ‘다독, 다작, 다상량’을 권장하지만, 시간을 내기 어려운 현실에서 회사의 '\n",
      " '지원이 필요하다.\\n'\n",
      " '\\n'\n",
      " '회사는 문해력 향상 프로그램을 제공하고, 독서 모임을 조직하며, 문서 작성 매뉴얼을 마련해야 한다. 이는 조직의 성과와 직결되며, '\n",
      " '장기적으로 회사의 발전에 도움이 된다. 문해력 문제는 개인의 책임으로 돌릴 수 없으며, 회사와 국가의 적극적인 대응이 필요하다.\\n'\n",
      " '\\n'\n",
      " '### 주요 내용 정리\\n'\n",
      " '\\n'\n",
      " '1. **독서 실태와 문해력 저하**:\\n'\n",
      " '   - 성인의 독서율, 독서량, 독서 시간이 감소하고 있음.\\n'\n",
      " '   - 성인 10명 중 6명이 1년 동안 책을 읽지 않음.\\n'\n",
      " '   - 문해력 저하로 인한 사회적 소통 문제 발생.\\n'\n",
      " '\\n'\n",
      " '2. **문해력의 중요성**:\\n'\n",
      " '   - 단순한 글 읽기, 쓰기를 넘어 맥락 이해와 의도 전달 능력 포함.\\n'\n",
      " '   - 성인의 문해력은 업무 능력과 직결되며, 세대 간 문해력 차이로 직장 내 소통 문제 발생.\\n'\n",
      " '\\n'\n",
      " '3. **비즈니스 현장에서의 필요성**:\\n'\n",
      " '   - 문해력 부족으로 인한 보고서 작성 문제와 상사와의 불화.\\n'\n",
      " '   - 한국은 세대 간 문해력 격차가 큰 나라로, 소통 문제와 갈등 초래.\\n'\n",
      " '\\n'\n",
      " '4. **회사 차원의 해결책**:\\n'\n",
      " '   - 문해력 향상 프로그램 제공.\\n'\n",
      " '   - 독서 모임 조직.\\n'\n",
      " '   - 문서 작성 매뉴얼 마련.\\n'\n",
      " '\\n'\n",
      " '5. **전문가 조언**:\\n'\n",
      " '   - ‘다독, 다작, 다상량’을 권장하지만 현실적으로 시간 부족 문제 존재.\\n'\n",
      " '   - 회사의 지원이 장기적으로 회사의 발전에 기여.\\n'\n",
      " '\\n'\n",
      " '6. **결론**:\\n'\n",
      " '   - 문해력 문제를 개인의 책임으로 돌릴 수 없으며, 회사와 국가의 적극적인 대응 필요.\\n'\n",
      " '\\n'\n",
      " '### 결론\\n'\n",
      " '\\n'\n",
      " '문해력 저하는 사회적 소통 문제를 야기하며, 이는 개인의 문제가 아닌 조직과 국가 전체의 문제로 인식되어야 한다. 장기적인 회사의 발전을 '\n",
      " '위해서라도 문해력 향상에 대한 체계적이고 전략적인 접근이 필요하다.')\n",
      "┌──────────────────────────────┐\n",
      "│         25.21원 사용          │\n",
      "└──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# gpt4 옴니 제로샷 시도\n",
    "zeroshot_prompt = PromptTemplate(\n",
    "    template=\"다음 아티클을 요약 및 정리해줘 : {article}\",\n",
    "    input_variables=[\"article\"]\n",
    ")\n",
    "chain = zeroshot_prompt | gpt4o\n",
    "with get_openai_callback() as cb:\n",
    "    resp = chain.invoke({\"article\": article})\n",
    "    pprint(resp.content)\n",
    "    convert_usd_to_krw(cb.total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('**Step 1:**\\n'\n",
      " '1-3 informative entities: \"문화체육관광부\"; \"성인 독서율\"; \"문해력 저하\"\\n'\n",
      " '\\n'\n",
      " '**Step 2:**\\n'\n",
      " '이 기사는 성인들의 문해력 저하 현상과 관련된 다양한 문제들을 다룹니다. 문화체육관광부가 발표한 2023년 국민 독서실태에 따르면 성인 '\n",
      " '독서율이 낮아지고 있으며, 이는 문해력 저하로 이어지고 있습니다. 문해력 저하는 사회적 소통에 큰 영향을 미치며, 비즈니스 현장에서도 '\n",
      " '중요한 문제로 부각되고 있습니다. 성인의 문해력을 향상시키기 위한 다양한 전략이 필요합니다.\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '**Step 1:**\\n'\n",
      " '1-3 informative entities: \"1년 동안 단 1권의 책도 읽지 않은\"; \"소통\"; \"보고서\"\\n'\n",
      " '\\n'\n",
      " '**Step 2:**\\n'\n",
      " '문화체육관광부가 발표한 2023년 국민 독서실태에 따르면 성인 독서율이 낮아지고 있으며, 성인 10명 중 6명은 1년 동안 단 1권의 '\n",
      " '책도 읽지 않았습니다. 이는 문해력 저하로 이어지고, 사회적 소통에 큰 영향을 미칩니다. 비즈니스 현장에서도 문해력은 중요하며, 보고서 '\n",
      " '작성과 같은 업무 능력과 직결됩니다. 성인의 문해력을 향상시키기 위한 다양한 전략이 필요합니다.\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '**Step 1:**\\n'\n",
      " '1-3 informative entities: \"OECD\"; \"MZ세대\"; \"독서 모임\"\\n'\n",
      " '\\n'\n",
      " '**Step 2:**\\n'\n",
      " '2023년 국민 독서실태에 따르면 성인 10명 중 6명은 1년 동안 단 1권의 책도 읽지 않았습니다. 이는 문해력 저하로 이어지며, '\n",
      " '사회적 소통과 비즈니스 현장에 영향을 미칩니다. OECD 조사에 따르면 한국은 세대 간 문해력 간격이 크며, 이는 MZ세대가 대기업을 '\n",
      " '떠나는 이유 중 하나입니다. 독서 모임과 같은 전략이 성인의 문해력 향상에 필요합니다.\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '**Step 1:**\\n'\n",
      " '1-3 informative entities: \"다독 다작 다상량\"; \"교정교열사\"; \"문해력 향상 프로그램\"\\n'\n",
      " '\\n'\n",
      " '**Step 2:**\\n'\n",
      " '2023년 국민 독서실태에 따르면 성인 10명 중 6명은 1년 동안 단 1권의 책도 읽지 않았습니다. 이는 문해력 저하로 이어지며, '\n",
      " '사회적 소통과 비즈니스 현장에 영향을 미칩니다. OECD 조사에 따르면 한국은 세대 간 문해력 간격이 크며, 이는 MZ세대가 대기업을 '\n",
      " '떠나는 이유 중 하나입니다. 다독 다작 다상량이 필요하며, 교정교열사와 문해력 향상 프로그램이 도움이 될 수 있습니다.\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '**Step 1:**\\n'\n",
      " '1-3 informative entities: \"직원의 문해력\"; \"회사 전략\"; \"공통적인 매뉴얼\"\\n'\n",
      " '\\n'\n",
      " '**Step 2:**\\n'\n",
      " '2023년 국민 독서실태에 따르면 성인 10명 중 6명은 1년 동안 단 1권의 책도 읽지 않았습니다. 이는 문해력 저하로 이어지며, '\n",
      " '사회적 소통과 비즈니스 현장에 영향을 미칩니다. OECD 조사에 따르면 한국은 세대 간 문해력 간격이 크며, 이는 MZ세대가 대기업을 '\n",
      " '떠나는 이유 중 하나입니다. 다독 다작 다상량이 필요하며, 교정교열사와 문해력 향상 프로그램이 도움이 됩니다. 직원의 문해력을 향상시키기 '\n",
      " '위한 회사 전략과 공통적인 매뉴얼이 필요합니다.')\n",
      "┌──────────────────────────────┐\n",
      "│         29.49원 사용          │\n",
      "└──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# gpt4 옴니 CoD 시도\n",
    "chain = prompt | gpt4o\n",
    "with get_openai_callback() as cb:\n",
    "    resp = chain.invoke({\"article\": article})\n",
    "    pprint(resp.content)\n",
    "    convert_usd_to_krw(cb.total_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "* CoV (Chain-of-Verification)\n",
    "\n",
    "설명: 답변을 단계별로 검증하는 기법입니다.\n",
    "핵심 개념: 각 단계에서의 논리적 일관성을 검증하며 최종 답을 도출합니다.\n",
    "고려사항: 각 단계의 검증 과정을 철저히 수행해야 하며, 모든 단계가 정확해야 최종 답변의 신뢰성이 보장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BTS는 대한민국의 7인조 보이 그룹으로, 방탄소년단 (Bangtan Sonyeondan)의 줄임말입니다. 그들은 2013년에 데뷔하여 '\n",
      " '국내외에서 큰 인기를 얻고 있는 그룹으로, 음악적인 업적 뿐만 아니라 사회공헌활동과 세계적인 영향력으로도 유명합니다. 그들은 다양한 음악 '\n",
      " '장르를 넘나들며 새로운 시도와 창의적인 음악으로 팬들을 매료시키고 있습니다. 또한, 그들은 UNICEF와 함께한 Love Myself '\n",
      " '캠페인을 통해 청소년들에게 긍정적인 메시지를 전달하고 있습니다. BTS는 K-pop 산업을 세계적으로 선도하는 그룹으로 평가받고 '\n",
      " '있습니다.')\n",
      "┌──────────────────────────────┐\n",
      "│          0.56원 사용          │\n",
      "└──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# gpt3.5 turbo 제로샷\n",
    "zeroshot_prompt = PromptTemplate(\n",
    "    template=\"다음에 대해 아는 것을 말해줘 : {topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "chain = zeroshot_prompt | gpt35\n",
    "with get_openai_callback() as cb:\n",
    "    resp = chain.invoke({\"topic\": \"BTS\"})\n",
    "    pprint(resp.content)\n",
    "    convert_usd_to_krw(cb.total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BTS는 한국의 보이 그룹으로, 방탄소년단(防彈少年團)의 줄임말이다. 2013년에 데뷔한 이후 꾸준한 인기를 얻어 세계적으로 유명한 '\n",
      " '아이돌 그룹으로 성장했다. BTS는 RM, 진, 슈가, 제이홉, 지민, 뷔, 정국으로 구성되어 있으며, 각 멤버들은 뛰어난 보컬 실력과 '\n",
      " '댄스 실력을 가지고 있다.\\n'\n",
      " '\\n'\n",
      " \"BTS는 음악뿐만 아니라 사회 문제에 대해 다뤄 노래하는 등의 특징을 가지고 있어, 팬들 사이에서는 '힙합몬스터', '천재 아이돌' 등의 \"\n",
      " '별명으로 불린다. 그들의 음악은 청소년들을 위로하고, 다양한 메시지를 전달하며 세계 각국의 팬들로부터 사랑을 받고 있다. 또한, '\n",
      " 'UNICEF와 함께 한 LOVE MYSELF 캠페인을 통해 아동학대 방지와 자해 예방을 위한 활동도 펼치고 있다. \\n'\n",
      " '\\n'\n",
      " 'BTS는 한국뿐만 아니라 전 세계적으로 많은 상을 수상하며 K-pop의 대표적인 아티스트로 자리매김했다. 그들의 음악은 언어의 장벽을 '\n",
      " '넘어 다양한 국가와 문화에서 사랑받고 있으며, 많은 이들에게 영감을 주고 희망을 전하고 있다. BTS는 그들만의 색깔과 메시지를 지닌 '\n",
      " '그룹으로서 음악적으로나 사회적으로 큰 영향력을 행사하고 있다.')\n",
      "┌──────────────────────────────┐\n",
      "│          1.18원 사용          │\n",
      "└──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# gpt3.5 turbo CoV (Chain-of-Verification)\n",
    "cov_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    1. 다음 주제에 대해 아는 것을 생성해봐 : {topic}. \n",
    "    2. 그리고 그 정보가 맞는지 검증하고 부족한 내용을 채우거나 잘못된 부분을 수정해줘.\n",
    "    3. 내용을 요약하지 말고 처음 생성한 분량만큼 풍성하게 작성해줘. \n",
    "    3. 수정된 최종 내용만 답변해줘.\n",
    "    \"\"\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "chain = cov_prompt | gpt35\n",
    "with get_openai_callback() as cb:\n",
    "    resp = chain.invoke({\"topic\": \"BTS\"})\n",
    "    pprint(resp.content)\n",
    "    convert_usd_to_krw(cb.total_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "* ToT (Tree-of-Thought) Prompting\n",
    "\n",
    "    * 방식 및 개념: 요청사항을 위한 다양한 경로를 탐색하고 각 경로의 결과를 비교 평가 후 최적의 추론 경로를 찾음\n",
    "  \n",
    "    * 특징: 복잡한 문제에서 특히 유용\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dante/miniconda3/envs/langchain/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "solution_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    다음 제시된 문제를 {count}가지의 고유한 해결 방법을 제시해줘. 함께 제시된 요소들을 고려해서 진행해줘.\n",
    "    * 문제: {problem}\n",
    "    * 요소: {factors}\n",
    "    \"\"\",\n",
    "    input_variables=[\"count\", \"problem\", \"factors\"]\n",
    ")\n",
    "\n",
    "solution_chain = LLMChain(llm=gpt35, prompt=solution_prompt, output_key=\"solutions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    제시된 해결 방법들을 각각 아래 항목으로 평가해줘\n",
    "    * 해결 방법: {solutions}\n",
    "    * 항목\n",
    "        1) 장점\n",
    "        2) 단점\n",
    "        3) 투입 에너지 대비 영향도\n",
    "        4) 현실성\n",
    "    * 평가 결과: \n",
    "    \"\"\",\n",
    "    input_variables=[\"solutions\"]\n",
    ")\n",
    "\n",
    "evaluation_chain = LLMChain(llm=gpt35, prompt=evaluation_prompt, output_key=\"evaluations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    각 평가 결과를 보고 시나리오, 구현 전략, 필요한 준비사항, 잠재 위험 해결 방법에 대해 가장 효과적인 해결방법을 추론하여 설명해줘.\n",
    "    * 평과 결과: {evaluations}\n",
    "    * 향상된 추론 목록: \n",
    "    \"\"\",\n",
    "    input_variables=[\"evaluations\"]\n",
    ")\n",
    "\n",
    "reasoning_chain = LLMChain(llm=gpt35, prompt=reasoning_prompt, output_key=\"improved_reasonings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    평가결과와 추론결과에 기반하여, 각 해결방법들의 순위를 매겨 순서대로 나열해줘.\n",
    "    * 향상된 추론 목록: {improved_reasonings}\n",
    "    \"\"\",\n",
    "    input_variables=[\"improved_reasonings\"]\n",
    ")\n",
    "\n",
    "ranking_chain = LLMChain(llm=gpt35, prompt=ranking_prompt, output_key=\"rankings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dante/miniconda3/envs/langchain/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1. 향상된 추론 목록\\n2. 시나리오\\n3. 구현 전략\\n4. 필요한 준비사항\\n5. 잠재 위험 해결 방법'\n"
     ]
    }
   ],
   "source": [
    "tot_chain = SequentialChain(\n",
    "    chains = [solution_chain, evaluation_chain, reasoning_chain, ranking_chain],\n",
    "    input_variables=[\"count\", \"problem\", \"factors\"],\n",
    "    output_variables=[\"rankings\"]\n",
    ")\n",
    "\n",
    "resp = tot_chain.run(\n",
    "    count=3,\n",
    "    problem=\"데이터 직무로 입사를 준비하고 있어. 그런데 잘 준비를 못한것 같아. 어떻게 준비하면 좋을까?\",\n",
    "    factors=\"면접, 코딩테스트, 자기소개서, 포트폴리오\"\n",
    ")\n",
    "\n",
    "pprint(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 순서대로 나열되긴 했으나, 항목명만 있고, 내용이 없는  답변이 나왔다.\n",
    "- Langsmith를 조회해보자.\n",
    "- https://smith.langchain.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "* Fine-Tuning\n",
    "    - 방식 및 개념 : 특정 작업에 대해 모델을 세부적으로 재학습시키는 기법. 특정 데이터셋을 사용하여 모델의 성능을 향상시킴\n",
    "    - 특징: 낮은 성능의 모델도 튜닝을 통해 해당 주제에 대한 높은 성능을 보장해줌. 단, 과적합을 방지하기 위한 적절한 규제가 필요\n",
    "\n",
    "___\n",
    "Fine-Tuning은 별도의 챕터에서 다루겠습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
