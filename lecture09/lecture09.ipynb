{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제9강. 추천 / 검색 모델의 성능평가 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from tqdm import trange\n",
    "from subprocess import call\n",
    "from scipy.sparse import csr_matrix, dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/ratings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1        1     4.0  964982703\n",
       "1        1        3     4.0  964981247\n",
       "2        1        6     4.0  964982224\n",
       "3        1       47     5.0  964983815\n",
       "4        1       50     5.0  964982931"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'movieId':'item_id', 'userId':'user_id'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(data, user_col, item_col, rating_col):\n",
    "    # map each item and user to a unique numeric value\n",
    "    for col in (item_col, user_col):\n",
    "        data[col] = data[col].astype('category')\n",
    "    \n",
    "    # create a sparse matrix of using the (rating, (rows, cols)) format\n",
    "    rows = data[user_col].cat.codes\n",
    "    cols = data[item_col].cat.codes\n",
    "    rating = data[rating_col]\n",
    "    ratings = csr_matrix((rating, (rows, cols)))\n",
    "    ratings.eliminate_zeros()\n",
    "    return ratings, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<610x9724 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 100836 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_col = 'user_id'\n",
    "item_col = 'item_id'\n",
    "rating_col = 'rating'\n",
    "X, df = create_matrix(df, user_col, item_col, rating_col)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(ratings, test_size = 0.2, seed = 1234):\n",
    "    assert test_size < 1.0 and test_size > 0.0\n",
    " \n",
    "    train = ratings.copy().todok()\n",
    "    test = dok_matrix(train.shape)\n",
    " \n",
    "    rstate = np.random.RandomState(seed)\n",
    "    for u in range(ratings.shape[0]):\n",
    "        split_index = ratings[u].indices\n",
    "        n_splits = ceil(test_size * split_index.shape[0])\n",
    "        test_index = rstate.choice(split_index, size = n_splits, replace = False)\n",
    "        test[u, test_index] = ratings[u, test_index]\n",
    "        train[u, test_index] = 0\n",
    "    \n",
    "    train, test = train.tocsr(), test.tocsr()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<610x9724 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 80419 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "test_size = 0.2\n",
    "X_train, X_test = create_train_test(X, test_size, seed)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALSWR:\n",
    "    def __init__(self, n_iters, n_factors, alpha, reg, seed):\n",
    "        self.reg = reg\n",
    "        self.seed = seed\n",
    "        self.alpha = alpha\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors\n",
    "    \n",
    "    def fit(self, ratings):\n",
    "        \"\"\"\n",
    "        ratings : scipy sparse csr_matrix [n_users, n_items]\n",
    "            sparse matrix of user-item interactions\n",
    "        \"\"\"        \n",
    "        Cui = ratings.copy().tocsr()\n",
    "        Cui.data *= self.alpha\n",
    "        Ciu = Cui.T.tocsr()\n",
    "        self.n_users, self.n_items = Cui.shape\n",
    "        \n",
    "        rstate = np.random.RandomState(self.seed)\n",
    "        self.user_factors = rstate.normal(size = (self.n_users, self.n_factors))\n",
    "        self.item_factors = rstate.normal(size = (self.n_items, self.n_factors))\n",
    "        \n",
    "        for _ in trange(self.n_iters, desc = 'training progress'):\n",
    "            self._als_step(Cui, self.user_factors, self.item_factors)\n",
    "            self._als_step(Ciu, self.item_factors, self.user_factors)  \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _als_step(self, Cui, X, Y):\n",
    "        \"\"\"\n",
    "        when solving the user latent vectors,\n",
    "        the item vectors will be fixed and vice versa\n",
    "        \"\"\"\n",
    "        YtY = Y.T.dot(Y)\n",
    "        data = Cui.data\n",
    "        indptr, indices = Cui.indptr, Cui.indices\n",
    " \n",
    "        for u in range(self.n_users):\n",
    "            # initialize a new A and b for every user\n",
    "            b = np.zeros(self.n_factors)\n",
    "            A = YtY + self.reg * np.eye(self.n_factors)\n",
    "            \n",
    "            for index in range(indptr[u], indptr[u + 1]):\n",
    "                # indices[index] stores non-zero positions for a given row\n",
    "                # data[index] stores corresponding confidence,\n",
    "                # we also add 1 to the confidence, since we did not \n",
    "                # do it in the beginning, when we were to give every \n",
    "                # user-item pair and minimal confidence\n",
    "                i = indices[index]\n",
    "                confidence = data[index] + 1\n",
    "                factor = Y[i]\n",
    "                \n",
    "                A += (confidence - 1) * np.outer(factor, factor)\n",
    " \n",
    "            X[u] = np.linalg.solve(A, b)\n",
    "        \n",
    "        return self\n",
    " \n",
    "    def predict(self):\n",
    "        \"\"\"predict ratings for every user and item\"\"\"\n",
    "        prediction = self.user_factors.dot(self.item_factors.T)\n",
    "        return prediction\n",
    "    \n",
    "    def _predict_user(self, user):\n",
    "        \"\"\"\n",
    "        returns the predicted ratings for the specified user,\n",
    "        this is mainly used in computing evaluation metric\n",
    "        \"\"\"\n",
    "        user_pred = self.user_factors[user].dot(self.item_factors.T)\n",
    "        return user_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training progress: 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ALSWR at 0x325aec050>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als = ALSWR(n_iters = 15, n_factors = 20, alpha = 15, reg = 0.01, seed = 1234)\n",
    "als.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## MAP (Mean Average Precision) 설명\n",
    "<img src=\"images/map1.webp\" style=\"background-color: white;\">\n",
    "\n",
    "#### 1. MAP의 정의\n",
    "- **MAP**은 여러 사용자 또는 쿼리에 대한 평균 정밀도(Average Precision, AP)의 평균입니다. 각 사용자 또는 쿼리별로 계산된 AP를 모두 합산한 후, 사용자 또는 쿼리의 총 수로 나누어 계산됩니다.\n",
    "\n",
    "#### 2. AP의 정의\n",
    "- **AP (Average Precision)** 는 특정 쿼리에 대한 검색 결과의 질을 나타내는 지표입니다. 관련 있는 항목들이 상위에 위치할수록 높은 값을 가집니다.\n",
    "- AP를 계산하는 공식:\n",
    "- 여기서 $k$는 고려한 결과 항목의 수입니다.\n",
    "\n",
    "#### 3. Precision과 Recall\n",
    "- **Precision at i**는 첫  $i$번째 항목까지의 정확한 추천 비율을 의미합니다. 즉, 첫 $i$개의 항목 중 정확하게 예측된 항목의 수를 $i$로 나눈 값입니다.\n",
    "- **Change in Recall at i**는 $i$번째 항목이 정확할 경우 증가하는 재현율의 변화량을 나타냅니다. 한 항목당 재현율의 증가는 $1/k$이며, $i$번째 항목이 정확하지 않은 경우 증가량은 0입니다.\n",
    "\n",
    "#### 4. 예시와 계산\n",
    "예를 들어, 실제 관련 데이터가 [1, 2, 3, 4, 5]이고 시스템이 [6, 4, 7, 1, 2]를 추천했다고 가정해보겠습니다.\n",
    "- 첫 번째 예측 6은 잘못되었으므로 precision@1은 0입니다.\n",
    "- 두 번째 예측 4는 정확하므로 precision@2는 0.5입니다 (1개 맞추고, 2개를 추천했으니까).\n",
    "- change in recall은 각각 0과 0.5입니다.\n",
    "- 따라서 AP@2는 $ \\frac{0}{1} + \\frac{0.5}{2} = 0.25$가 됩니다.\n",
    "\n",
    "#### 5. 순의 중요성\n",
    "- AP 및 MAP에서는 추천된 항목의 순서가 중요합니다. 잘못된 추측이 먼저 나오면 precision의 값이 감소하므로, 정확한 추천을 가능한 앞쪽에 위치시키는 것이 중요합니다.\n",
    "\n",
    "이러한 방식으로 MAP는 복잡한 정보 환경에서 사용자에게 유용하고 정확한 정보를 제공하는 시스템의 능력을 정량적으로 평가하는 데 매우 유용한 메트릭입니다.\n",
    "\n",
    "\n",
    "#### 6. 장단점\n",
    "* 장점\n",
    "    ```\n",
    "    단순성과 직관성: MAP는 계산이 단순하며 결과를 해석하기 쉬워, 많은 연구 및 산업 분야에서 선호됩니다.\n",
    "    정확성 중시: 관련성 있는 항목의 개수와 그 순서를 고려하여 평균 정밀도를 계산하기 때문에, 추천 시스템이 얼마나 정확한 정보를 제공하는지를 효과적으로 측정합니다.\n",
    "    이진 관련성: 항목이 관련성이 있는지 여부만 판단하므로, 평가가 비교적 명확합니다.\n",
    "    ```\n",
    "* 단점\n",
    "    ```\n",
    "    순위 민감도 부족: 첫 번째로 제공되는 항목과 마지막으로 제공되는 항목의 중요성 차이를 충분히 반영하지 못합니다.\n",
    "    이진 관련성의 한계: 실제로 많은 항목들이 다양한 수준의 관련성을 가질 수 있는데, MAP는 이를 구분하지 못하고 단순히 관련성 있는 항목으로만 취급합니다.\n",
    "    ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_apk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    average precision at k, y_pred is assumed \n",
    "    to be truncated to length k prior to feeding\n",
    "    it to the function\n",
    "    \"\"\"\n",
    "    # convert to set since membership \n",
    "    # testing in a set is vastly faster\n",
    "    actual = set(y_true)\n",
    "    \n",
    "    # precision at i is a percentage of correct \n",
    "    # items among first i recommendations; the\n",
    "    # correct count will be summed up by n_hit\n",
    "    n_hit = 0\n",
    "    precision = 0\n",
    "    for i, p in enumerate(y_pred, 1):\n",
    "        if p in actual:\n",
    "            n_hit += 1\n",
    "            precision += n_hit / i\n",
    " \n",
    "    avg_precision = precision / min(len(actual), k)\n",
    "    return avg_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example 1\n",
    " \n",
    "k = 2\n",
    "y_true = np.array([1, 2, 3, 4, 5])\n",
    "y_pred = np.array([6, 4, 7, 1, 2])\n",
    "compute_apk(y_true, y_pred[:k], k) # 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.325"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example 2\n",
    " \n",
    "k = 5\n",
    "y_true = np.array([1, 2])\n",
    "y_pred = np.array([6, 4, 7, 1, 2])\n",
    "compute_apk(y_true, y_pred[:k], k) # 0.325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapk_score(model, ratings, k):\n",
    "    \"\"\"\n",
    "    mean average precision at rank k for the ALS model\n",
    " \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : ALSWR instance\n",
    "        fitted ALSWR model\n",
    " \n",
    "    ratings : scipy sparse csr_matrix [n_users, n_items]\n",
    "        sparse matrix of user-item interactions\n",
    " \n",
    "    k : int\n",
    "        mean average precision at k's k\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    mapk : float\n",
    "        the mean average precision at k's score\n",
    "    \"\"\"\n",
    "    # compare the top k predictions' index to the actual index,\n",
    "    # the model is assumed to have the _predict_user method\n",
    "    mapk = 0\n",
    "    n_users = ratings.shape[0]\n",
    "    for u in range(n_users):\n",
    "        y_true = ratings[u].indices\n",
    "        u_pred = model._predict_user(u)\n",
    "        y_pred = np.argsort(u_pred)[::-1][:k]\n",
    "        mapk += compute_apk(y_true, y_pred, k)\n",
    " \n",
    "    mapk /= n_users\n",
    "    return mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP@5 training: 0.0013715846994535518\n",
      "mAP@5 testing: 6.557377049180328e-05\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "mapk_train = mapk_score(als, X_train, k)\n",
    "mapk_test = mapk_score(als, X_test, k)\n",
    "print('mAP@5 training:', mapk_train)\n",
    "print('mAP@5 testing:', mapk_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## NDCG (Normalized Discounted Cumulative Gain) 설명\n",
    "<img src=\"images/ndcg.webp\" style=\"background-color: white;\">\n",
    "\n",
    "#### 1. Cumulative Gain (CG)의 정의\n",
    "- **Cumulative Gain (CG)** 는 특정 순위 \\( k \\)까지의 결과에 대해 각 항목의 관련성(relevance) 점수를 단순히 합산한 값입니다. CG 계산에서는 항목의 순서가 결과 값에 영향을 주지 않습니다.\n",
    "- CG는 다음과 같이 정의됩니다.\n",
    "   - $\\color{yellow}{CG_k = \\sum_{i=1}^{k} relevance_i}$\n",
    "\n",
    "#### 2. Discounted Cumulative Gain (DCG)\n",
    "- **DCG**는 순위를 고려한 측정 지표로, 상위 순위의 항목이 더 중요하다는 가정 하에 점수를 계산합니다.\n",
    "- 각 관련성 점수는 순위에 따른 감쇠(discount)를 적용받아 합산됩니다. 이 감쇠는 일반적으로 항목 위치의 로그에 따라 적용됩니다.\n",
    "- DCG는 다음과 같이 정의됩니다\n",
    "\n",
    "   - $\\color{yellow}{DCG_k = \\sum_{i=1}^{k} \\frac{relevance_i}{\\log_2(i+1)}}$\n",
    "\n",
    "여기서 \\( i \\)는 항목의 순위를 나타내며, \\( k \\)는 고려된 결과 항목의 수입니다.\n",
    "\n",
    "#### 3. Normalized DCG (NDCG)\n",
    "- **NDCG**는 DCG 값을 최대 가능한 DCG 값(이상적인 순서에서의 DCG)으로 나눈 것입니다.\n",
    "- NDCG의 계산은 현재의 DCG를 이상적인 DCG와 비교하여 시스템의 이상적인 성능 대비 실제 성능을 평가합니다.\n",
    "- NDCG의 계산 공식은 다음과 같습니다:\n",
    "  \n",
    "   - $\\color{yellow}{NDCG_k = \\frac{DCG_k}{IDCG_k}}$\n",
    "\n",
    "여기서 \\( IDCG_k \\)는 \\( k \\)개의 최고 관련성 점수가 이상적인 순서로 배열된 경우의 DCG 값입니다.\n",
    "\n",
    "#### 4. 순위의 중요성\n",
    "\n",
    "- NDCG에서는 가장 관련성 높은 아이템이 높은 순위에 오를수록 더 높은 점수를 받습니다. 이는 검색 결과의 질을 더욱 신뢰성 있게 반영합니다.\n",
    "- NDCG는 추천 시스템의 정확성뿐만 아니라 그 정렬 순서의 적합성까지 고려할 수 있는 유용한 평가 방법입니다.\n",
    "\n",
    "#### 5. 장단점\n",
    "* 장점\n",
    "    ```\n",
    "    순위 중요성 반영: NDCG는 항목의 순위에 따라 가중치를 다르게 적용하여 상위 순위의 항목이 더 중요하게 평가됩니다. 이로 인해 결과의 순위에 대한 성능을 더 정확하게 반영할 수 있습니다.\n",
    "    다양한 관련성 수준 처리: 각 항목의 관련성을 다양한 수치로 표현할 수 있어, 단순 이진 평가보다 더 세밀한 평가가 가능합니다.\n",
    "    정규화를 통한 비교 용이성: 최대 DCG 값으로 정규화함으로써, 다른 쿼리 또는 시스템 간의 성능을 공정하게 비교할 수 있습니다.\n",
    "    ```\n",
    "* 단점\n",
    "    ```\n",
    "    계산 복잡성: 로그 함수를 사용한 할인율 계산으로 인해 MAP보다 계산이 복잡합니다.\n",
    "    최적 값 의존성: 최적의 DCG 값(IDCG)에 의존하여 계산되므로, 이 값의 정확성이 결과의 신뢰도에 큰 영향을 미칩니다.\n",
    "    ```\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.361353116146786"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dcg_at_k(score, k = None):\n",
    "    if k is not None:\n",
    "        score = score[:k]\n",
    " \n",
    "    discounts = np.log2(np.arange(2, score.size + 2))\n",
    "    dcg = np.sum(score / discounts)\n",
    "    return dcg\n",
    " \n",
    " \n",
    "score = np.array([2, 0, 3, 2])\n",
    "dcg_at_k(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8288615669472547"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ndcg_at_k(score, k = None):\n",
    "    actual_dcg = dcg_at_k(score, k)\n",
    "    sorted_score = np.sort(score)[::-1]\n",
    "    best_dcg = dcg_at_k(sorted_score, k)\n",
    "    ndcg = actual_dcg / best_dcg\n",
    "    return ndcg\n",
    " \n",
    " \n",
    "ndcg_at_k(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_score(model, ratings, k):\n",
    "    \"\"\"\n",
    "    Normalized discounted cumulative gain (NDCG) at rank k\n",
    "    for the ALS model; which computes the ndcg score for\n",
    "    each users' recommendation and does a simply average\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : ALSWR instance\n",
    "        fitted ALSWR model\n",
    " \n",
    "    ratings : scipy sparse csr_matrix [n_users, n_items]\n",
    "        sparse matrix of user-item interactions\n",
    " \n",
    "    k : int\n",
    "        rank k's k\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    avg_ndcg : float\n",
    "        ndcg at k's score averaged across all users\n",
    "    \"\"\"\n",
    "    ndcg = 0.0\n",
    "    n_users, n_items = ratings.shape\n",
    "    for u in range(n_users):\n",
    "        y_true = np.zeros(n_items)\n",
    "        y_true[ratings[u].indices] = 1\n",
    "        u_pred = model._predict_user(u)\n",
    "        ndcg += ndcg_at_k(y_true, u_pred, k)\n",
    "        \n",
    "    avg_ndcg = ndcg / n_users\n",
    "    return avg_ndcg\n",
    " \n",
    " \n",
    "def ndcg_at_k(y_true, y_score, k = 10):\n",
    "    \"\"\"\n",
    "    Normalized discounted cumulative gain (NDCG) at rank k\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like, shape = [n_samples]\n",
    "        Ground truth (true relevance labels)\n",
    "    \n",
    "    y_score : array-like, shape = [n_samples]\n",
    "        Predicted scores\n",
    "    \n",
    "    k : int\n",
    "        Rank\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    ndcg : float, 0.0 ~ 1.0\n",
    "    \"\"\"\n",
    "    actual = dcg_at_k(y_true, y_score, k)\n",
    "    best = dcg_at_k(y_true, y_true, k) \n",
    "    ndcg = actual / best\n",
    "    return ndcg\n",
    " \n",
    " \n",
    "def dcg_at_k(y_true, y_score, k = 10):\n",
    "    \"\"\"\n",
    "    Discounted cumulative gain (DCG) at rank k\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like, shape = [n_samples]\n",
    "        Ground truth (true relevance labels)\n",
    "    \n",
    "    y_score : array-like, shape = [n_samples]\n",
    "        Predicted scores\n",
    "    \n",
    "    k : int\n",
    "        Rank\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    dcg : float\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(2, gains.size + 2))\n",
    "    dcg = np.sum(gains / discounts)\n",
    "    return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg training: 0.002864981492034436\n",
      "ndcg testing: 0.000215090291003839\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "ndcg_train = ndcg_score(als, X_train, k)\n",
    "ndcg_test = ndcg_score(als, X_test, k)\n",
    "print('ndcg training:', ndcg_train)\n",
    "print('ndcg testing:', ndcg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 수업내용 Reference\n",
    " - Hu, Y., Koren, Y., & Volinsky, C. (2008, December). Collaborative filtering for implicit feedback datasets. In 2008 Eighth IEEE international conference on data mining (pp. 263-272). Ieee.\n",
    " - https://en.wikipedia.org/wiki/Discounted_cumulative_gain\n",
    " - http://fastml.com/evaluating-recommender-systems/\n",
    " - https://gist.github.com/mblondel/7337391\n",
    " - http://ethen8181.github.io/machine-learning/recsys/2_implicit.html\n",
    " - https://ysg2997.tistory.com/39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "#### # 과제#4. KMU-TRIP ( https://yangang.co.kr ) 에 접속해 개인당 최소 10회 이상 검색어를 입력하여 검색하고 선호하는 숙소를 장바구니 버튼을 클릭해주세요.\n",
    "    - 다음시간에 생성된 데이터로 검색 성능을 평가해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "#### # KMU-TRIP 검색 데이터 조회 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install psycopg2\n",
    "# !pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url = 'postgresql://kmu.nyytaxrizjztsgcmrlnj:kmu@aws-0-ap-northeast-2.pooler.supabase.com:5432/postgres' # 수업내용을 위해 데이터 조회 권한이 부여된 계정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(jdbc_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_df = pd.read_sql_table('hotels', engine)\n",
    "clicks_df = pd.read_sql_table('clicks', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "수고하셨습니다\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
